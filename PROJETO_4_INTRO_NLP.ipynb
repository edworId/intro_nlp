{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PROJETO INTRO NLP**"
      ],
      "metadata": {
        "id": "dl58V816XY4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Este projeto utilizado como projeto de estudos para a área de Machine Learning, NLP e Data Science com intuito de demonstrar conhecimento sobre os assuntos.**\n",
        "\n",
        "**Elaborado por EDMUNDO LOPES SILVA**\n",
        "\n",
        "[LINKEDIN](https://www.linkedin.com/in/edmundo-lopes-silva-7ab3b4163/)"
      ],
      "metadata": {
        "id": "YWdPCn_lXhO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP (Natural Language Processing), ou Processamento de Linguagem Natural, é uma subárea da inteligência artificial (IA) que se concentra em permitir que computadores compreendam, interpretem e respondam à linguagem humana de forma que seja útil. O objetivo do NLP é fazer com que as máquinas interajam com o texto ou fala humana de maneira semelhante ao comportamento humano, utilizando algoritmos de aprendizado de máquina e regras linguísticas."
      ],
      "metadata": {
        "id": "AWf3YmpBXmWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicações de NLP:\n",
        "\n",
        "1. Assistentes Virtuais (Chatbots)\n",
        "2. Análise de Sentimentos\n",
        "3. Tradução Automática\n",
        "4. Classificação de Textos\n",
        "5. Reconhecimento de Fala\n",
        "6. Resumo Automático de Textos\n",
        "7. Correção Ortográfica e Gramatical\n"
      ],
      "metadata": {
        "id": "YgSTofrzX9Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Principais Tarefas do NLP:\n",
        "1. Tokenização\n",
        "  \n",
        " - Dividir um texto em unidades menores (palavras, subpalavras ou caracteres) para análise.\n",
        "2. Lematização:\n",
        "\n",
        " - Lematização: Reduzir palavras às suas formas base ou raiz (ex.: \"correr\" em vez de \"correndo\").\n",
        "3. Stemming:\n",
        "\n",
        " - Stemming: Cortar as terminações das palavras para chegar à raiz (ex.: \"corr\" em vez de \"correndo\").\n",
        "\n",
        "4. Análise Sintática (Parsing):\n",
        "\n",
        " - Analisar a estrutura gramatical de frases para entender como as palavras se relacionam entre si.\n",
        "\n",
        "5. Reconhecimento de Entidades Nomeadas (NER):\n",
        "\n",
        "  - Identificar entidades como nomes de pessoas, locais e organizações em um texto.\n",
        "\n",
        "6. Análise de Sentimentos:\n",
        "\n",
        " - Determinar a opinião ou emoção expressa em um texto, como se é positiva, negativa ou neutra.\n",
        "\n",
        "7. Tradução Automática:\n",
        "\n",
        "  - Converter textos de um idioma para outro.\n",
        "\n",
        "8. Detecção de Spam:\n",
        "\n",
        " - Identificar automaticamente mensagens de spam.\n",
        "\n",
        "9. Classificação de Textos:\n",
        "\n",
        " - Classificar documentos em categorias, como emails, notícias ou resenhas de produtos.\n",
        "\n"
      ],
      "metadata": {
        "id": "65EgdvbvYlby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install nltk spacy\n",
        "# !python -m spacy download en_core_web_sm # SE PRECISAR BAIXAR O MODELO, NÃO PRECISA NO COLAB NOTEBOOK"
      ],
      "metadata": {
        "id": "nckgFZVFUCQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTAÇÃO DAS BIBLIOTECAS NECESSÁRIAS\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.util import ngrams # N-GRAMS\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer # STEMMING\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize # TOKENIZE"
      ],
      "metadata": {
        "id": "FKU3htvJUFDa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BAIXAR PACOTES NECESSÁRIOS NLTK\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tju-Ojl_Uqav",
        "outputId": "d8640f13-d685-47b6-e638-71a4cf5c7b8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo spaCy para lematização\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "CtxEuHrBUsan"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TEXTO QUE IREMOS TRATAR, LEMBRANDO QUE DEVEMOS TER UM TEXTO QUE REFERE AO IDIOMA DO MODELO\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dogs. He is running fast, faster than ever before.\""
      ],
      "metadata": {
        "id": "1WmHBZ1lU5gU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOKENIZAÇÃO"
      ],
      "metadata": {
        "id": "_T3f5YxnfbkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenização é o processo de dividir um texto em unidades menores chamadas tokens. Esses tokens podem ser palavras, frases ou até mesmo subpalavras e caracteres, dependendo da abordagem. É uma etapa fundamental no Processamento de Linguagem Natural (NLP) porque facilita a análise e manipulação de textos ao separar as informações em partes menores e mais gerenciáveis.\n",
        "\n",
        "Tipos de Tokenização\n",
        "- Tokenização de Palavras: O texto é dividido em palavras individuais. Por exemplo:\n",
        "\n",
        " - Texto: \"A raposa rápida pula sobre o cão preguiçoso.\"\n",
        " - Tokens: [\"A\", \"raposa\", \"rápida\", \"pula\", \"sobre\", \"o\", \"cão\", \"preguiçoso\"]\n",
        "\n",
        "- Tokenização de Frases: O texto é dividido em frases. Isso é útil quando se deseja analisar a estrutura de frases inteiras, como em resumos ou análise de sentimentos.\n",
        "\n",
        " - Texto: \"A raposa rápida pula sobre o cão preguiçoso. Ele não se mexeu.\"\n",
        " - Tokens: [\"A raposa rápida pula sobre o cão preguiçoso.\", \"Ele não se mexeu.\"]\n",
        "\n",
        "- Tokenização Sub-Palavra: Em algumas aplicações (como modelos BERT ou GPT), as palavras são divididas em subunidades menores, como morfemas ou pedaços de palavras. Isso permite o processamento de palavras desconhecidas ou palavras raras.\n",
        "\n",
        " - Palavra: \"incrível\"\n",
        " - Tokens: [\"in\", \"cri\", \"vel\"]\n",
        "\n",
        "- Tokenização de Caracteres: O texto é dividido em caracteres individuais, útil em tarefas como modelagem de linguagens para alfabetos não-latinos ou na geração de texto.\n",
        "\n",
        " - Texto: \"ChatGPT\"\n",
        " - Tokens: [\"C\", \"h\", \"a\", \"t\", \"G\", \"P\", \"T\"]\n",
        "\n",
        "**Importância da Tokenização**\n",
        "\n",
        "A tokenização é essencial porque muitos algoritmos de NLP operam em uma sequência de tokens em vez do texto bruto. Ao quebrar o texto em tokens, os modelos conseguem:\n",
        "\n",
        "- Analisar e processar cada unidade individualmente.\n",
        "- Entender a relação entre palavras.\n",
        "- Aplicar técnicas como stemming, lematização ou n-grams a essas unidades.\n"
      ],
      "metadata": {
        "id": "3SJ_OkhTfdkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AQUI VAMOS FAZER A TOKENIZAÇÃO COM EXEMPLOS DE TOKENIZE DE PALAVRAS E FRASES\n",
        "\n",
        "word_tokens = word_tokenize(text)\n",
        "print(\"Tokens de palavras:\", word_tokens)\n",
        "\n",
        "sentence_tokens = sent_tokenize(text)\n",
        "print(\"Tokens de frases:\", sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OPTTYX4VCMj",
        "outputId": "b188c185-9407-441b-9d76-99bbad7fa17f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens de palavras: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dogs', '.', 'He', 'is', 'running', 'fast', ',', 'faster', 'than', 'ever', 'before', '.']\n",
            "Tokens de frases: ['The quick brown fox jumps over the lazy dogs.', 'He is running fast, faster than ever before.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEMMING"
      ],
      "metadata": {
        "id": "JmOh5s2oa4ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming é uma técnica em Processamento de Linguagem Natural (NLP) usada para reduzir palavras derivadas às suas formas básicas ou \"raiz\". O objetivo do stemming é remover os sufixos das palavras, deixando apenas o radical, ou seja, a parte mais essencial da palavra. Isso ajuda a normalizar diferentes formas de uma mesma palavra para que possam ser tratadas como equivalentes durante a análise de texto.\n",
        "\n",
        "O algoritmo de stemming funciona removendo sufixos e, às vezes, prefixos, de uma palavra para chegar à sua forma de raiz. Por exemplo, as palavras \"correr\", \"correndo\", \"correu\", \"corre\" podem ser todas reduzidas ao radical \"corr\" através do processo de stemming.\n",
        "\n",
        "EXEMPLO: RUNNING - RUN"
      ],
      "metadata": {
        "id": "pM7v4_aDa77e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AQUI TEREMOS O STEMMING\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stems = [ps.stem(word) for word in word_tokens]\n",
        "print(\"Stemming:\", stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NFOI9YVVFUB",
        "outputId": "4cd88c24-4a82-4ec0-8a06-f062b54804f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming: ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazi', 'dog', '.', 'he', 'is', 'run', 'fast', ',', 'faster', 'than', 'ever', 'befor', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LEMATIZAÇÃO"
      ],
      "metadata": {
        "id": "heaYOc0lbbt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lematização é uma técnica de Processamento de Linguagem Natural (NLP) que transforma uma palavra em sua forma base ou dicionária (chamada de lema), considerando o contexto gramatical da palavra. Ao contrário do stemming, que simplesmente remove sufixos para encontrar a raiz da palavra, a lematização usa regras linguísticas e informações morfológicas, como a classe gramatical, para identificar a forma correta de uma palavra."
      ],
      "metadata": {
        "id": "KPOKbnYQba4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AQUI TEREMOS A LEMATIZAÇÃO\n",
        "\n",
        "# LEMATIZAÇÃO COM SPACY\n",
        "\n",
        "doc = nlp(text)\n",
        "lemmas_spacy = [token.lemma_ for token in doc]\n",
        "print(text)\n",
        "print(\"Lematização com spaCy:\", lemmas_spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvQg0W1yVlDu",
        "outputId": "1084fb76-6b81-4cce-b94b-70cb2632ed78"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumps over the lazy dogs. He is running fast, faster than ever before.\n",
            "Lematização com spaCy: ['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog', '.', 'he', 'be', 'run', 'fast', ',', 'fast', 'than', 'ever', 'before', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIFERENÇA ENTRE LEMATIZAÇÃO E STEMMING"
      ],
      "metadata": {
        "id": "QvDordkKb4KC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming: Simplesmente corta a palavra até o seu radical, sem se preocupar se a forma resultante é um termo real ou uma palavra válida.\n",
        "\n",
        "- \"correndo\", \"correu\", \"correrá\" → \"corr\"\n",
        "- \"melhores\" → \"melhor\"\n",
        "\n",
        "Lematização: Reduz as palavras à sua forma dicionária ou básica, considerando o contexto gramatical para garantir que a palavra resultante seja um termo correto.\n",
        "\n",
        "- \"correndo\", \"correu\", \"correrá\" → \"correr\"\n",
        "- \"melhores\" → \"bom\""
      ],
      "metadata": {
        "id": "DtGrVFLtb_bZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARSING"
      ],
      "metadata": {
        "id": "qnc1LHBObf_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parsing é o processo de análise de uma estrutura linguística ou sintática de uma sequência de palavras ou símbolos, seja em linguagem natural (como inglês ou português) ou em linguagem de programação. O objetivo do parsing é decompor uma frase em seus componentes gramaticais, como substantivos, verbos, preposições, etc., para entender a relação entre esses elementos e a função que desempenham na sentença."
      ],
      "metadata": {
        "id": "iObUhC6bcp2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dada a frase:\n",
        "\n",
        " \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "Um parser pode identificar:\n",
        "\n",
        "The (Artigo)\n",
        "quick (Adjetivo)\n",
        "fox (Substantivo)\n",
        "jumps (Verbo)\n",
        "over (Preposição)\n",
        "dog (Substantivo)\n",
        "\n",
        "Além de identificar as partes do discurso, o parser também analisará como essas palavras se relacionam entre si. Por exemplo, pode determinar que \"fox\" é o sujeito do verbo \"jumps\", ou que \"lazy\" está modificando \"dog\"."
      ],
      "metadata": {
        "id": "Oa0xzAOwcwf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AQUI TEREMOS O PARSING\n",
        "\n",
        "# PARSING COM SPACY USANDO doc = nlp(text)\n",
        "\n",
        "print(\"\\nParsing e Análise Sintática:\")\n",
        "for token in doc:\n",
        "    print(f\"Palavra: {token.text} | POS: {token.pos_} | Dependência: {token.dep_} | Raiz: {token.head.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slOzwX2dZnvH",
        "outputId": "4b76ee8b-d4fa-4d1f-8aba-ab6d59686f9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parsing e Análise Sintática:\n",
            "Palavra: The | POS: DET | Dependência: det | Raiz: fox\n",
            "Palavra: quick | POS: ADJ | Dependência: amod | Raiz: fox\n",
            "Palavra: brown | POS: ADJ | Dependência: amod | Raiz: fox\n",
            "Palavra: fox | POS: NOUN | Dependência: nsubj | Raiz: jumps\n",
            "Palavra: jumps | POS: VERB | Dependência: ROOT | Raiz: jumps\n",
            "Palavra: over | POS: ADP | Dependência: prep | Raiz: jumps\n",
            "Palavra: the | POS: DET | Dependência: det | Raiz: dogs\n",
            "Palavra: lazy | POS: ADJ | Dependência: amod | Raiz: dogs\n",
            "Palavra: dogs | POS: NOUN | Dependência: pobj | Raiz: over\n",
            "Palavra: . | POS: PUNCT | Dependência: punct | Raiz: jumps\n",
            "Palavra: He | POS: PRON | Dependência: nsubj | Raiz: running\n",
            "Palavra: is | POS: AUX | Dependência: aux | Raiz: running\n",
            "Palavra: running | POS: VERB | Dependência: ROOT | Raiz: running\n",
            "Palavra: fast | POS: ADV | Dependência: advmod | Raiz: running\n",
            "Palavra: , | POS: PUNCT | Dependência: punct | Raiz: running\n",
            "Palavra: faster | POS: ADV | Dependência: advmod | Raiz: running\n",
            "Palavra: than | POS: ADP | Dependência: prep | Raiz: faster\n",
            "Palavra: ever | POS: ADV | Dependência: advmod | Raiz: before\n",
            "Palavra: before | POS: ADV | Dependência: pcomp | Raiz: than\n",
            "Palavra: . | POS: PUNCT | Dependência: punct | Raiz: running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-GRAMS"
      ],
      "metadata": {
        "id": "AC78K7XQbikC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-gram é um conceito utilizado em Processamento de Linguagem Natural (NLP) para representar uma sequência de elementos (normalmente palavras ou caracteres) em um texto. O número de elementos na sequência é determinado pelo valor de N.\n",
        "\n",
        "Os N-grams capturam a relação entre palavras que estão próximas umas das outras em um texto. Isso ajuda a capturar o contexto local, especialmente em análises onde a ordem das palavras é importante.\n",
        "\n",
        "Exemplo de N-grams:\n",
        "\n",
        "Dada a frase: \"Eu gosto de aprender NLP\".\n",
        "\n",
        "- Unigram: [\"Eu\", \"gosto\", \"de\", \"aprender\", \"NLP\"]\n",
        "- Bigram: [\"Eu gosto\", \"gosto de\", \"de aprender\", \"aprender NLP\"]\n",
        "- Trigram: [\"Eu gosto de\", \"gosto de aprender\", \"de aprender NLP\"]\n",
        "\n",
        "Desvantagem do n-grams é uma explosão combinatória, na medida que N aumenta, o número de N-grams possíveis cresce exponencialmente, o que pode levar a modelos grandes e lentos. Além disso, há uma perda de contexto global já que N-grams com N pequeno (como bigram ou trigram) capturam apenas uma visão local, e não conseguem capturar dependências de longo alcance no texto.\n"
      ],
      "metadata": {
        "id": "8xHT-9yydUmE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC506pezTPs7",
        "outputId": "1d17d381-5df5-4eac-f378-adff906e52a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigramas: [('The', 'quick'), ('quick', 'brown'), ('brown', 'fox'), ('fox', 'jumps'), ('jumps', 'over'), ('over', 'the'), ('the', 'lazy'), ('lazy', 'dogs'), ('dogs', '.'), ('.', 'He'), ('He', 'is'), ('is', 'running'), ('running', 'fast'), ('fast', ','), (',', 'faster'), ('faster', 'than'), ('than', 'ever'), ('ever', 'before'), ('before', '.')]\n",
            "Trigramas: [('The', 'quick', 'brown'), ('quick', 'brown', 'fox'), ('brown', 'fox', 'jumps'), ('fox', 'jumps', 'over'), ('jumps', 'over', 'the'), ('over', 'the', 'lazy'), ('the', 'lazy', 'dogs'), ('lazy', 'dogs', '.'), ('dogs', '.', 'He'), ('.', 'He', 'is'), ('He', 'is', 'running'), ('is', 'running', 'fast'), ('running', 'fast', ','), ('fast', ',', 'faster'), (',', 'faster', 'than'), ('faster', 'than', 'ever'), ('than', 'ever', 'before'), ('ever', 'before', '.')]\n"
          ]
        }
      ],
      "source": [
        "# AQUI FAREMOS O N-GRAMS COM BIGRAMS E TRIGRAMS\n",
        "\n",
        "bigrams = list(ngrams(word_tokens, 2))\n",
        "print(\"Bigramas:\", bigrams)\n",
        "\n",
        "trigrams = list(ngrams(word_tokens, 3))\n",
        "print(\"Trigramas:\", trigrams)"
      ]
    }
  ]
}